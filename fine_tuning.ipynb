{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e87da79-a4b7-4a6b-813d-cf382185c10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-11 19:20:08.206102: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-11 19:20:08.257563: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras import Input, Model\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "30bc5bbc-6ef4-40f6-8d72-d13f8b0e4160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1e545b4b-006d-4244-9283-6b317420293d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_character_bounding_boxes(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    thresh = cv2.threshold(gray, 0, 255,\n",
    "        cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "    output = cv2.connectedComponentsWithStats(\n",
    "        thresh, 8, cv2.CV_32S)\n",
    "    (numLabels, labels, stats, centroids) = output\n",
    "    new_stats = []\n",
    "    added = [False for i in range(len(stats))]\n",
    "    threshhold = .5\n",
    "    for i in range(1,len(stats)):\n",
    "        if added[i]:\n",
    "            continue\n",
    "\n",
    "        (xi, yi, wi, hi, ai) = stats[i]\n",
    "        for j  in range(i+1,len(stats)):\n",
    "            if added[j]:\n",
    "                continue\n",
    "\n",
    "            (xj, yj, wj, hj, aj) = stats[j]\n",
    "            if xi<=xj:\n",
    "                if xi+wi>=xj+wj:\n",
    "                    hi = max(yi+hi,yj+hj)\n",
    "                    yi = min(yi,yj)\n",
    "                    hi = hi-yi\n",
    "                    ai += aj\n",
    "                    added[j] = True\n",
    "                elif xi+wi>=xj:\n",
    "                    o = xi+wi-xj\n",
    "                    if o/wi>threshhold or o/wj>threshhold:\n",
    "                        wi = xj+wj-xi\n",
    "                        hi = max(yi+hi,yj+hj)\n",
    "                        yi = min(yi,yj)\n",
    "                        hi = hi-yi\n",
    "                        ai += aj\n",
    "                        added[j] = True\n",
    "\n",
    "            if xj<xi:\n",
    "                if xj+wj>=xi+wi:\n",
    "                    xi = xj\n",
    "                    wi = wj\n",
    "                    hi = max(yi+hi,yj+hj)\n",
    "                    yi = min(yi,yj)\n",
    "                    hi = hi-yi\n",
    "                    ai += aj\n",
    "                    added[j] = True\n",
    "                elif xj+wj>=xi:\n",
    "                    o = xj+wj-xi\n",
    "                    if o/wi>threshhold or o/wj>threshhold:\n",
    "                        wi = xj+wj-xi\n",
    "                        hi = max(yi+hi,yj+hj)\n",
    "                        yi = min(yi,yj)\n",
    "                        hi = hi-yi\n",
    "                        ai += aj\n",
    "                        added[j] = True\n",
    "\n",
    "        new_stats.append([xi, yi, wi, hi, ai])\n",
    "        added[i] = True\n",
    "\n",
    "    new_stats = sorted(new_stats, key=lambda x: x[0])\n",
    "    return new_stats\n",
    "\n",
    "def save_symbol_as_image(location, name, img, bounding_box):\n",
    "    (x, y, w, h, a) = bounding_box\n",
    "    cropped = img[y:y+h, x:x+w]\n",
    "    cropped = cv2.resize(cropped, (28, 28))\n",
    "    cv2.imwrite(location + '/' + name + '.png', cropped)\n",
    "    return cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "459c117a-aa28-4879-b16f-91c17e08aa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_image(img, threshold=127):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply thresholding with background-foreground inversion\n",
    "    binary_img = cv2.threshold(img, threshold, 1, cv2.THRESH_BINARY_INV)[1]\n",
    "\n",
    "    return binary_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "fc0f624a-87d7-4127-9b21-fa9a5a63f7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_split(dir_path):\n",
    "    Path(\"./data/fine-tune processed\").mkdir(parents=True, exist_ok=True)\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_test = []\n",
    "    y_test = []\n",
    "    \n",
    "    for root, directories, files in os.walk(dir_path):\n",
    "        for subfolder in directories:\n",
    "            class_name = subfolder\n",
    "            if '.ipynb_checkpoints' in class_name:\n",
    "                continue\n",
    "            class_folder_location = f\"./data/fine-tune processed/{class_name}\"\n",
    "            Path(class_folder_location).mkdir(parents=True, exist_ok=True)\n",
    "            count = 0\n",
    "            processed_img = []\n",
    "            \n",
    "            for img_file in os.listdir(os.path.join(root, subfolder)):\n",
    "                if '.ipynb_checkpoints' in img_file or 'image-checkpoint' in img_file:\n",
    "                    continue\n",
    "                img_path = os.path.join(root, subfolder, img_file)\n",
    "                im = cv2.imread(img_path)\n",
    "                print(img_path)\n",
    "                boxes = get_character_bounding_boxes(im)\n",
    "                \n",
    "                for box in boxes:\n",
    "                    symbol_img = save_symbol_as_image(class_folder_location, class_name + '_' + str(count), im, box)\n",
    "                    symbol_img = binarize_image(symbol_img)\n",
    "                    processed_img.append(symbol_img)\n",
    "                    count += 1\n",
    "\n",
    "            train_imgs, test_imgs = train_test_split(processed_img, train_size=0.8)\n",
    "            x_train += train_imgs\n",
    "            y_train += [class_name for _ in range(len(train_imgs))]\n",
    "            x_test += test_imgs\n",
    "            y_test += [class_name for _ in range(len(test_imgs))]\n",
    "                    \n",
    "    return np.array(x_train), np.array(y_train), np.array(x_test), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f528b947-ca90-4e0f-8996-2496e3797733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/fine-tune unprocessed/6/image5.jpg\n",
      "./data/fine-tune unprocessed/6/image6.jpg\n",
      "./data/fine-tune unprocessed/6/image3.jpg\n",
      "./data/fine-tune unprocessed/6/image2.jpg\n",
      "./data/fine-tune unprocessed/6/image0.jpg\n",
      "./data/fine-tune unprocessed/6/image7.jpg\n",
      "./data/fine-tune unprocessed/6/image4.jpg\n",
      "./data/fine-tune unprocessed/6/image9.jpg\n",
      "./data/fine-tune unprocessed/6/image1.jpg\n",
      "./data/fine-tune unprocessed/6/image8.jpg\n",
      "./data/fine-tune unprocessed/+/image5.jpg\n",
      "./data/fine-tune unprocessed/+/image6.jpg\n",
      "./data/fine-tune unprocessed/+/image3.jpg\n",
      "./data/fine-tune unprocessed/+/image2.jpg\n",
      "./data/fine-tune unprocessed/+/image0.jpg\n",
      "./data/fine-tune unprocessed/+/image7.jpg\n",
      "./data/fine-tune unprocessed/+/image4.jpg\n",
      "./data/fine-tune unprocessed/+/image9.jpg\n",
      "./data/fine-tune unprocessed/+/image1.jpg\n",
      "./data/fine-tune unprocessed/+/image8.jpg\n",
      "./data/fine-tune unprocessed/-/image5.jpg\n",
      "./data/fine-tune unprocessed/-/image6.jpg\n",
      "./data/fine-tune unprocessed/-/image3.jpg\n",
      "./data/fine-tune unprocessed/-/image2.jpg\n",
      "./data/fine-tune unprocessed/-/image0.jpg\n",
      "./data/fine-tune unprocessed/-/image7.jpg\n",
      "./data/fine-tune unprocessed/-/image4.jpg\n",
      "./data/fine-tune unprocessed/-/image9.jpg\n",
      "./data/fine-tune unprocessed/-/image1.jpg\n",
      "./data/fine-tune unprocessed/-/image8.jpg\n",
      "./data/fine-tune unprocessed/2/image10.jpg\n",
      "./data/fine-tune unprocessed/2/image5.jpg\n",
      "./data/fine-tune unprocessed/2/image6.jpg\n",
      "./data/fine-tune unprocessed/2/image3.jpg\n",
      "./data/fine-tune unprocessed/2/image2.jpg\n",
      "./data/fine-tune unprocessed/2/image11.jpg\n",
      "./data/fine-tune unprocessed/2/image0.jpg\n",
      "./data/fine-tune unprocessed/2/image7.jpg\n",
      "./data/fine-tune unprocessed/2/image4.jpg\n",
      "./data/fine-tune unprocessed/2/image9.jpg\n",
      "./data/fine-tune unprocessed/2/image1.jpg\n",
      "./data/fine-tune unprocessed/2/image8.jpg\n",
      "./data/fine-tune unprocessed/8/image5.jpg\n",
      "./data/fine-tune unprocessed/8/image6.jpg\n",
      "./data/fine-tune unprocessed/8/image3.jpg\n",
      "./data/fine-tune unprocessed/8/image2.jpg\n",
      "./data/fine-tune unprocessed/8/image0.jpg\n",
      "./data/fine-tune unprocessed/8/image7.jpg\n",
      "./data/fine-tune unprocessed/8/image4.jpg\n",
      "./data/fine-tune unprocessed/8/image9.jpg\n",
      "./data/fine-tune unprocessed/8/image1.jpg\n",
      "./data/fine-tune unprocessed/8/image8.jpg\n",
      "./data/fine-tune unprocessed/3/image5.jpg\n",
      "./data/fine-tune unprocessed/3/image6.jpg\n",
      "./data/fine-tune unprocessed/3/image3.jpg\n",
      "./data/fine-tune unprocessed/3/image2.jpg\n",
      "./data/fine-tune unprocessed/3/image0.jpg\n",
      "./data/fine-tune unprocessed/3/image7.jpg\n",
      "./data/fine-tune unprocessed/3/image4.jpg\n",
      "./data/fine-tune unprocessed/3/image9.jpg\n",
      "./data/fine-tune unprocessed/3/image1.jpg\n",
      "./data/fine-tune unprocessed/3/image8.jpg\n",
      "./data/fine-tune unprocessed/5/image5.jpg\n",
      "./data/fine-tune unprocessed/5/image6.jpg\n",
      "./data/fine-tune unprocessed/5/image3.jpg\n",
      "./data/fine-tune unprocessed/5/image2.jpg\n",
      "./data/fine-tune unprocessed/5/image0.jpg\n",
      "./data/fine-tune unprocessed/5/image7.jpg\n",
      "./data/fine-tune unprocessed/5/image4.jpg\n",
      "./data/fine-tune unprocessed/5/image9.jpg\n",
      "./data/fine-tune unprocessed/5/image1.jpg\n",
      "./data/fine-tune unprocessed/5/image8.jpg\n",
      "./data/fine-tune unprocessed/[/image5.jpg\n",
      "./data/fine-tune unprocessed/[/image6.jpg\n",
      "./data/fine-tune unprocessed/[/image3.jpg\n",
      "./data/fine-tune unprocessed/[/image2.jpg\n",
      "./data/fine-tune unprocessed/[/image0.jpg\n",
      "./data/fine-tune unprocessed/[/image7.jpg\n",
      "./data/fine-tune unprocessed/[/image4.jpg\n",
      "./data/fine-tune unprocessed/[/image9.jpg\n",
      "./data/fine-tune unprocessed/[/image1.jpg\n",
      "./data/fine-tune unprocessed/[/image8.jpg\n",
      "./data/fine-tune unprocessed/7/image5.jpg\n",
      "./data/fine-tune unprocessed/7/image6.jpg\n",
      "./data/fine-tune unprocessed/7/image3.jpg\n",
      "./data/fine-tune unprocessed/7/image2.jpg\n",
      "./data/fine-tune unprocessed/7/image0.jpg\n",
      "./data/fine-tune unprocessed/7/image7.jpg\n",
      "./data/fine-tune unprocessed/7/image4.jpg\n",
      "./data/fine-tune unprocessed/7/image9.jpg\n",
      "./data/fine-tune unprocessed/7/image1.jpg\n",
      "./data/fine-tune unprocessed/7/image8.jpg\n",
      "./data/fine-tune unprocessed/%/image5.jpg\n",
      "./data/fine-tune unprocessed/%/image6.jpg\n",
      "./data/fine-tune unprocessed/%/image3.jpg\n",
      "./data/fine-tune unprocessed/%/image2.jpg\n",
      "./data/fine-tune unprocessed/%/image0.jpg\n",
      "./data/fine-tune unprocessed/%/image7.jpg\n",
      "./data/fine-tune unprocessed/%/image4.jpg\n",
      "./data/fine-tune unprocessed/%/image9.jpg\n",
      "./data/fine-tune unprocessed/%/image1.jpg\n",
      "./data/fine-tune unprocessed/%/image8.jpg\n",
      "./data/fine-tune unprocessed/9/image5.jpg\n",
      "./data/fine-tune unprocessed/9/image6.jpg\n",
      "./data/fine-tune unprocessed/9/image3.jpg\n",
      "./data/fine-tune unprocessed/9/image2.jpg\n",
      "./data/fine-tune unprocessed/9/image0.jpg\n",
      "./data/fine-tune unprocessed/9/image7.jpg\n",
      "./data/fine-tune unprocessed/9/image4.jpg\n",
      "./data/fine-tune unprocessed/9/image9.jpg\n",
      "./data/fine-tune unprocessed/9/image1.jpg\n",
      "./data/fine-tune unprocessed/9/image8.jpg\n",
      "./data/fine-tune unprocessed/0/image5.jpg\n",
      "./data/fine-tune unprocessed/0/image6.jpg\n",
      "./data/fine-tune unprocessed/0/image.png\n",
      "./data/fine-tune unprocessed/0/image2.png\n",
      "./data/fine-tune unprocessed/0/image7.jpg\n",
      "./data/fine-tune unprocessed/0/image1.png\n",
      "./data/fine-tune unprocessed/0/image4.jpg\n",
      "./data/fine-tune unprocessed/0/image9.jpg\n",
      "./data/fine-tune unprocessed/0/image3.png\n",
      "./data/fine-tune unprocessed/0/image8.jpg\n",
      "./data/fine-tune unprocessed/4/image5.jpg\n",
      "./data/fine-tune unprocessed/4/image6.jpg\n",
      "./data/fine-tune unprocessed/4/image3.jpg\n",
      "./data/fine-tune unprocessed/4/image2.jpg\n",
      "./data/fine-tune unprocessed/4/image0.jpg\n",
      "./data/fine-tune unprocessed/4/image7.jpg\n",
      "./data/fine-tune unprocessed/4/image4.jpg\n",
      "./data/fine-tune unprocessed/4/image9.jpg\n",
      "./data/fine-tune unprocessed/4/image1.jpg\n",
      "./data/fine-tune unprocessed/4/image8.jpg\n",
      "./data/fine-tune unprocessed/1/image5.jpg\n",
      "./data/fine-tune unprocessed/1/image6.jpg\n",
      "./data/fine-tune unprocessed/1/image3.jpg\n",
      "./data/fine-tune unprocessed/1/image2.jpg\n",
      "./data/fine-tune unprocessed/1/image0.jpg\n",
      "./data/fine-tune unprocessed/1/image7.jpg\n",
      "./data/fine-tune unprocessed/1/image4.jpg\n",
      "./data/fine-tune unprocessed/1/image9.jpg\n",
      "./data/fine-tune unprocessed/1/image1.jpg\n",
      "./data/fine-tune unprocessed/1/image8.jpg\n",
      "./data/fine-tune unprocessed/*/image5.jpg\n",
      "./data/fine-tune unprocessed/*/image6.jpg\n",
      "./data/fine-tune unprocessed/*/image3.jpg\n",
      "./data/fine-tune unprocessed/*/image2.jpg\n",
      "./data/fine-tune unprocessed/*/image0.jpg\n",
      "./data/fine-tune unprocessed/*/image7.jpg\n",
      "./data/fine-tune unprocessed/*/image4.jpg\n",
      "./data/fine-tune unprocessed/*/image9.jpg\n",
      "./data/fine-tune unprocessed/*/image1.jpg\n",
      "./data/fine-tune unprocessed/*/image8.jpg\n",
      "./data/fine-tune unprocessed/]/image5.jpg\n",
      "./data/fine-tune unprocessed/]/image6.jpg\n",
      "./data/fine-tune unprocessed/]/image3.jpg\n",
      "./data/fine-tune unprocessed/]/image2.jpg\n",
      "./data/fine-tune unprocessed/]/image0.jpg\n",
      "./data/fine-tune unprocessed/]/image7.jpg\n",
      "./data/fine-tune unprocessed/]/image4.jpg\n",
      "./data/fine-tune unprocessed/]/image9.jpg\n",
      "./data/fine-tune unprocessed/]/image1.jpg\n",
      "./data/fine-tune unprocessed/]/image8.jpg\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = extract_and_split('./fine-tune-dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7114a18a-e6c9-440b-9e11-8ebc926a1e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2560, 28, 28, 1) (642, 28, 28, 1)\n",
      "(2560,) (642,)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "print(x_train.shape, x_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "f7dc351b-3900-4ba7-85ab-093e7d3b5ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'%': 0, '*': 1, '+': 2, '-': 3, '0': 4, '1': 5, '2': 6, '3': 7, '4': 8, '5': 9, '6': 10, '7': 11, '8': 12, '9': 13, '[': 14, ']': 15}\n",
    "reverse_mapping = {0: '%', 1: '*', 2: '+', 3: '-', 4: '0', 5: '1', 6: '2', 7: '3', 8: '4', 9: '5', 10: '6', 11: '7', 12: '8', 13: '9', 14: '[', 15: ']'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "1b96dab9-ac1f-438d-9298-62d0e9392ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_transform(x):\n",
    "    transformed = [mapping[y] for y in x]\n",
    "    return np.array(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d67f61fe-2f24-4c20-80fc-c2e24c806a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = custom_transform(y_train)\n",
    "y_test = custom_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "7ac76707-4f1a-4f25-92c6-8ff430f75cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2560,)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "db46647a-4349-4ccc-beab-e219ec0fe6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "MATH_best = load_model('MATH.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b3e4bee7-a33f-40b1-9c3a-dc4110281279",
   "metadata": {},
   "outputs": [],
   "source": [
    "MATH_best.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e15b38bf-84ce-4a10-ac76-d953236c5021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers in the base model:  9\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of layers in the base model: \", len(MATH_best.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "a425a319-5a65-4520-b3e0-9c086256172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_at = 4\n",
    "for layer in MATH_best.layers[:fine_tune_at]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "cfdf300e-b58d-465b-be68-4164c4bad907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 20)        520       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 28, 28, 20)        10020     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 20)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 14, 14, 50)        25050     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 14, 14, 50)        62550     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 50)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2450)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 500)               1225500   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                8016      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,331,656\n",
      "Trainable params: 1,296,066\n",
      "Non-trainable params: 35,590\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MATH_best.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "MATH_best.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "2d30ef0b-01e1-4675-8f6c-51c7eb3758d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "9/9 - 2s - loss: 0.7839 - accuracy: 0.9347 - val_loss: 13.3131 - val_accuracy: 0.2786 - 2s/epoch - 246ms/step\n",
      "Epoch 2/20\n",
      "9/9 - 1s - loss: 0.0248 - accuracy: 0.9954 - val_loss: 16.8011 - val_accuracy: 0.1719 - 1s/epoch - 147ms/step\n",
      "Epoch 3/20\n",
      "9/9 - 2s - loss: 0.0059 - accuracy: 0.9982 - val_loss: 17.6239 - val_accuracy: 0.1719 - 2s/epoch - 168ms/step\n",
      "Epoch 4/20\n",
      "9/9 - 1s - loss: 0.0019 - accuracy: 0.9991 - val_loss: 17.7358 - val_accuracy: 0.1589 - 1s/epoch - 152ms/step\n",
      "Epoch 5/20\n",
      "9/9 - 1s - loss: 2.0818e-04 - accuracy: 1.0000 - val_loss: 17.8214 - val_accuracy: 0.1641 - 1s/epoch - 140ms/step\n",
      "Epoch 6/20\n",
      "9/9 - 1s - loss: 1.2476e-04 - accuracy: 1.0000 - val_loss: 17.8524 - val_accuracy: 0.1667 - 1s/epoch - 141ms/step\n",
      "Epoch 7/20\n",
      "9/9 - 1s - loss: 7.8355e-05 - accuracy: 1.0000 - val_loss: 17.8633 - val_accuracy: 0.1667 - 1s/epoch - 146ms/step\n",
      "Epoch 8/20\n",
      "9/9 - 1s - loss: 5.7267e-05 - accuracy: 1.0000 - val_loss: 17.8536 - val_accuracy: 0.1667 - 1s/epoch - 150ms/step\n",
      "Epoch 9/20\n",
      "9/9 - 1s - loss: 4.6059e-05 - accuracy: 1.0000 - val_loss: 17.8291 - val_accuracy: 0.1667 - 1s/epoch - 132ms/step\n",
      "Epoch 10/20\n",
      "9/9 - 1s - loss: 3.7225e-05 - accuracy: 1.0000 - val_loss: 17.8292 - val_accuracy: 0.1667 - 1s/epoch - 148ms/step\n",
      "Epoch 11/20\n",
      "9/9 - 1s - loss: 3.3345e-05 - accuracy: 1.0000 - val_loss: 17.8120 - val_accuracy: 0.1693 - 1s/epoch - 149ms/step\n",
      "Epoch 12/20\n",
      "9/9 - 1s - loss: 2.9740e-05 - accuracy: 1.0000 - val_loss: 17.7884 - val_accuracy: 0.1667 - 1s/epoch - 144ms/step\n",
      "Epoch 13/20\n",
      "9/9 - 1s - loss: 2.5973e-05 - accuracy: 1.0000 - val_loss: 17.7697 - val_accuracy: 0.1667 - 1s/epoch - 146ms/step\n",
      "Epoch 14/20\n",
      "9/9 - 1s - loss: 2.3497e-05 - accuracy: 1.0000 - val_loss: 17.7489 - val_accuracy: 0.1667 - 1s/epoch - 140ms/step\n",
      "Epoch 15/20\n",
      "9/9 - 1s - loss: 2.1572e-05 - accuracy: 1.0000 - val_loss: 17.7367 - val_accuracy: 0.1667 - 1s/epoch - 148ms/step\n",
      "Epoch 16/20\n",
      "9/9 - 1s - loss: 1.9719e-05 - accuracy: 1.0000 - val_loss: 17.7375 - val_accuracy: 0.1667 - 1s/epoch - 147ms/step\n",
      "Epoch 17/20\n",
      "9/9 - 1s - loss: 1.7817e-05 - accuracy: 1.0000 - val_loss: 17.7176 - val_accuracy: 0.1641 - 1s/epoch - 144ms/step\n",
      "Epoch 18/20\n",
      "9/9 - 1s - loss: 1.6278e-05 - accuracy: 1.0000 - val_loss: 17.6918 - val_accuracy: 0.1641 - 1s/epoch - 151ms/step\n",
      "Epoch 19/20\n",
      "9/9 - 1s - loss: 1.4886e-05 - accuracy: 1.0000 - val_loss: 17.6575 - val_accuracy: 0.1641 - 1s/epoch - 150ms/step\n",
      "Epoch 20/20\n",
      "9/9 - 1s - loss: 1.3568e-05 - accuracy: 1.0000 - val_loss: 17.6480 - val_accuracy: 0.1641 - 1s/epoch - 153ms/step\n"
     ]
    }
   ],
   "source": [
    "hist = MATH_best.fit(x_train, y_train, epochs=20, validation_split=0.15, verbose=2, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "bd16755a-36a5-4f67-a43b-b350367e5799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 1s 13ms/step - loss: 2.6472 - accuracy: 0.8746\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.7031 - accuracy: 0.8723\n",
      "train acc 0.8746093511581421\n",
      "test acc 0.8722741603851318\n"
     ]
    }
   ],
   "source": [
    "loss_train,train_acc = MATH_best.evaluate(x_train, y_train)\n",
    "loss_test,test_acc   = MATH_best.evaluate(x_test, y_test)\n",
    "print('train acc', train_acc)\n",
    "print('test acc', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "bccdccbd-07d8-476f-b276-5d4e3723fddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_fine_tuning = load_model('MATH.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "40883c3a-e6bc-431d-bc42-cd03a938afc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 1s 12ms/step - loss: 4.7033 - accuracy: 0.6969\n",
      "21/21 [==============================] - 1s 14ms/step - loss: 5.1122 - accuracy: 0.6854\n",
      "train acc 0.6968749761581421\n",
      "test acc 0.6853582262992859\n"
     ]
    }
   ],
   "source": [
    "loss_train,train_acc = before_fine_tuning.evaluate(x_train, y_train)\n",
    "loss_test,test_acc   = before_fine_tuning.evaluate(x_test, y_test)\n",
    "print('train acc', train_acc)\n",
    "print('test acc', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "bc20d30e-aa45-4ce8-8401-fb8baffec6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "MATH_best.save(\"fine_tuned_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "ca5ad892-188c-4690-bc02-160c9ff3fded",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path('./data/fine-tune-complete').mkdir(parents=True, exist_ok=True)\n",
    "with open('./data/fine-tune-complete/x_train.npy', 'wb+') as f:\n",
    "    np.save(f, x_train)\n",
    "with open('./data/fine-tune-complete/y_train.npy', 'wb+') as f:\n",
    "    np.save(f, y_train)\n",
    "with open('./data/fine-tune-complete/x_test.npy', 'wb+') as f:\n",
    "    np.save(f, x_test)\n",
    "with open('./data/fine-tune-complete/y_test.npy', 'wb+') as f:\n",
    "    np.save(f, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "4bd5e407-8251-4fee-b6a6-28d0dbf200ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "MATH_best = load_model('./fine_tuned_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "2b003c1e-3873-4974-94b6-f2ba9b2d5a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['handwritten-full-test/.ipynb_checkpoints',\n",
       " 'handwritten-full-test/x+9.jpg',\n",
       " 'handwritten-full-test/6_div_3.jpg',\n",
       " 'handwritten-full-test/1+1=.jpg',\n",
       " 'handwritten-full-test/8+4.jpg',\n",
       " 'handwritten-full-test/1+1.jpg',\n",
       " 'handwritten-full-test/3.3.jpg',\n",
       " 'handwritten-full-test/2x2.jpg']"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_dir = 'handwritten-full-test'\n",
    "images = [f.path for f in os.scandir(images_dir)]\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "bb85caa3-fc44-40f6-8e02-a839ffb260cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = images[5]\n",
    "img = cv2.imread(img)\n",
    "bbs = get_character_bounding_boxes(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "39f82989-bbb3-4882-8730-7a2f6d9cae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input_img(img, bb):\n",
    "    (x, y, w, h, a) = bb\n",
    "    cropped = img[y:y+h, x:x+w]\n",
    "    cropped = cv2.resize(cropped, (28, 28))\n",
    "    return binarize_image(cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "4fd0f8b5-d6c6-4f7e-996e-724ccc47b4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 52ms/step\n",
      "1\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "+\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for bb in bbs:\n",
    "    char = format_input_img(img, bb)\n",
    "    char = char.reshape(-1, 28, 28, 1) \n",
    "    yh_test = MATH_best.predict(char).argmax(axis=1)\n",
    "    print(reverse_mapping[yh_test[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4775166f-5a98-4dde-8cf5-1d40c198a8a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
