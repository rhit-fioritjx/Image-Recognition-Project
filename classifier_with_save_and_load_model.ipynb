{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b783c2c1-6924-45c5-8fdb-8a253e3e5eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_162929/4134392719.py:5: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "\n",
    "device = torch.device('cuda:1')\n",
    "# torch.cuda.set_device(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a449852f-eca2-446b-bd9c-ce97a11b7ae3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # used to unzip files in server\n",
    "# from zipfile import ZipFile\n",
    "# # specifying the zip file name \n",
    "# file_name = \"data_processed.zip\"\n",
    "  \n",
    "# # opening the zip file in READ mode \n",
    "# with ZipFile(file_name, 'r') as zip: \n",
    "#     # printing all the contents of the zip file \n",
    "#     zip.printdir() \n",
    "  \n",
    "#     # extracting all the files \n",
    "#     print('Extracting all the files now...') \n",
    "#     zip.extractall() \n",
    "#     print('Done!') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce73ecb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dcb392c-d4df-4b4d-aff6-bd0724da133b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_split(data_path, ignore_classes=[]):\n",
    "        x_train = []\n",
    "        x_test = []\n",
    "        y_train = []\n",
    "        y_test = []\n",
    "        subfolders = [f.path for f in os.scandir(data_path) if f.is_dir()]\n",
    "        \n",
    "        for subfolder in subfolders:\n",
    "            class_name = subfolder.split('/')[-1]\n",
    "            if class_name in ignore_classes:\n",
    "                continue\n",
    "\n",
    "            files_in_subfolder = [f.path for f in os.scandir(subfolder) if f.is_file() and (f.name.endswith('.jpg') or f.name.endswith('.png'))]\n",
    "\n",
    "            train_files, test_files = train_test_split(files_in_subfolder, train_size=0.8)\n",
    "            x_train += train_files\n",
    "            x_test += test_files\n",
    "            y_train += [class_name] * len(train_files)\n",
    "            y_test += [class_name] * len(test_files)\n",
    "\n",
    "        return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01cd07ba-8a05-4991-b43e-84401060565d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1, x_test1, y_train1, y_test1 = extract_and_split(\"./dataset/\", ignore_classes=[])\n",
    "x_train2, x_test2, y_train2, y_test2 = extract_and_split('./data_processed/', ignore_classes=[])\n",
    "x_train = x_train1 + x_train2\n",
    "y_train = y_train1 + y_train2\n",
    "x_test = x_test1 + x_test2\n",
    "y_test = y_test1 + y_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23e764ff-98ab-4b9d-8191-4c68d555516c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map class names to integers\n",
    "all_classes = np.unique(y_train + y_test)\n",
    "mapping = {class_name.item(): idx for idx, class_name in enumerate(all_classes)}\n",
    "rev_mapping = {idx: class_name for class_name, idx in mapping.items()}\n",
    "\n",
    "y_train = torch.tensor([mapping[class_name] for class_name in y_train])\n",
    "y_test = torch.tensor([mapping[class_name] for class_name in y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7d16d82-e202-441f-bbcd-a24aef6fbeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_list, labels, transforms):\n",
    "        super(MyDataset, self).__init__()\n",
    "        self.img_list = img_list\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.img_list[idx]\n",
    "        img = Image.open(img).convert('L')\n",
    "        return self.transforms(img), self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74e36a4d-c58b-4324-91d2-6c54f0e64f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(155, 135)\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=155x135>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path = x_train[456]\n",
    "image = Image.open(img_path)\n",
    "print(image.size)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dbd06b1-ea7b-4a62-8f42-2bcc67523f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "train_dataset = MyDataset(x_train, y_train, transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataset = MyDataset(x_test, y_test, transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80cb142e-ac50-4260-b5b9-bc91bae42655",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1b583ec-b9c6-4ba2-a454-192be4d5128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_channels = 1\n",
    "conv_layers = nn.Sequential(\n",
    "    nn.Conv2d(input_channels, 16, 3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 32, 3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(32, 64, 3, padding=1),\n",
    "    nn.ReLU()\n",
    ")\n",
    "\n",
    "# Calculate the size of the output of the conv_layers by doing one forward pass\n",
    "dummy_input = torch.randn(1, input_channels, 128, 128)\n",
    "output = conv_layers(dummy_input)\n",
    "conv_out = output.shape[1] * output.shape[2] * output.shape[3]\n",
    "\n",
    "model = nn.Sequential(\n",
    "    conv_layers,\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(conv_out, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, num_classes)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "835fd8a3-0a75-4bc0-b4a2-bf093f122cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed8e1cf1-e048-4be3-a0bd-5eb46428420d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b57097f4-420d-4645-b1d2-8177371b5d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (1): Flatten(start_dim=1, end_dim=-1)\n",
       "  (2): Linear(in_features=1048576, out_features=128, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (5): ReLU()\n",
       "  (6): Linear(in_features=128, out_features=85, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53123343-9f13-44c2-9a62-0705194e0a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load existing model, skip the training block to go straight to testing, remember to ensure that the structure match the .txt file\n",
    "# model.load_state_dict(torch.load(\"data_processed_model8774.pth\"))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f372274c-0d96-4b8c-8af4-2a236740fff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_162929/2846701550.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs, labels = inputs.to(device), torch.tensor(labels).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Train Loss: 0.9382, Train Accuracy: 0.7615, Test Accuracy: 0.8530\n",
      "Epoch [2/2], Train Loss: 0.3395, Train Accuracy: 0.8995, Test Accuracy: 0.8630\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    # Training Phase\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    total_train_correct = 0\n",
    "    total_test_correct = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Convert outputs probabilities to predicted class\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        # Calculate correct predictions\n",
    "        total_train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), torch.tensor(labels).to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        # Convert outputs probabilities to predicted class\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        # Calculate correct predictions\n",
    "        total_test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    train_accuracy = total_train_correct / len(train_loader.dataset)\n",
    "    test_accuracy = total_test_correct / len(test_loader.dataset)\n",
    "\n",
    "    # Print epoch summary\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47b9fda2-4a00-4f6d-9e58-c1a5ef103c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_162929/1784268762.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs, labels = inputs.to(device), torch.tensor(labels).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4806, Test Accuracy: 0.8630\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "total_loss = 0\n",
    "total_correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), torch.tensor(labels).to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Convert outputs probabilities to predicted class\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        # Calculate correct predictions\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "\n",
    "avg_loss = total_loss / len(test_loader)\n",
    "accuracy = total_correct / len(test_loader.dataset)\n",
    "\n",
    "print(f'Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5164a637-63e4-4d11-9157-e4f42006e4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: sqrt, Actual: sqrt\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=128x128>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get random test image\n",
    "img, label = test_dataset[random.randint(0, len(test_dataset))]\n",
    "\n",
    "pred = model(img.unsqueeze(0).to(device))\n",
    "_, pred = torch.max(pred, 1)\n",
    "print(f\"Predicted: {rev_mapping[pred.item()]}, Actual: {rev_mapping[label.item()]}\")\n",
    "\n",
    "# convert img to PIL image\n",
    "img = img.squeeze(0)\n",
    "img = transforms.ToPILImage()(img)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7afd8460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model to file\n",
    "torch.save(model.state_dict(), \"both_dataset_model8630.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5f7805-b6e5-43c8-b8e0-2747d54b7522",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
