{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d377c86-b79b-4373-9a33-ec74ed0cf196",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 19:43:13.788513: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-12 19:43:13.838815: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras import Input, Model\n",
    "import os\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b316fc6-c711-4101-a8bf-393aeab4d5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_character_bounding_boxes(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    thresh = cv2.threshold(gray, 0, 255,\n",
    "        cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "    output = cv2.connectedComponentsWithStats(\n",
    "        thresh, 8, cv2.CV_32S)\n",
    "    (numLabels, labels, stats, centroids) = output\n",
    "    new_stats = []\n",
    "    added = [False for i in range(len(stats))]\n",
    "    threshhold = .5\n",
    "    for i in range(1,len(stats)):\n",
    "        if added[i]:\n",
    "            continue\n",
    "\n",
    "        (xi, yi, wi, hi, ai) = stats[i]\n",
    "        for j  in range(i+1,len(stats)):\n",
    "            if added[j]:\n",
    "                continue\n",
    "\n",
    "            (xj, yj, wj, hj, aj) = stats[j]\n",
    "            if xi<=xj:\n",
    "                if xi+wi>=xj+wj:\n",
    "                    hi = max(yi+hi,yj+hj)\n",
    "                    yi = min(yi,yj)\n",
    "                    hi = hi-yi\n",
    "                    ai += aj\n",
    "                    added[j] = True\n",
    "                elif xi+wi>=xj:\n",
    "                    o = xi+wi-xj\n",
    "                    if o/wi>threshhold or o/wj>threshhold:\n",
    "                        wi = xj+wj-xi\n",
    "                        hi = max(yi+hi,yj+hj)\n",
    "                        yi = min(yi,yj)\n",
    "                        hi = hi-yi\n",
    "                        ai += aj\n",
    "                        added[j] = True\n",
    "\n",
    "            if xj<xi:\n",
    "                if xj+wj>=xi+wi:\n",
    "                    xi = xj\n",
    "                    wi = wj\n",
    "                    hi = max(yi+hi,yj+hj)\n",
    "                    yi = min(yi,yj)\n",
    "                    hi = hi-yi\n",
    "                    ai += aj\n",
    "                    added[j] = True\n",
    "                elif xj+wj>=xi:\n",
    "                    o = xj+wj-xi\n",
    "                    if o/wi>threshhold or o/wj>threshhold:\n",
    "                        wi = xj+wj-xi\n",
    "                        hi = max(yi+hi,yj+hj)\n",
    "                        yi = min(yi,yj)\n",
    "                        hi = hi-yi\n",
    "                        ai += aj\n",
    "                        added[j] = True\n",
    "\n",
    "        new_stats.append([xi, yi, wi, hi, ai])\n",
    "        added[i] = True\n",
    "\n",
    "    new_stats = sorted(new_stats, key=lambda x: x[0])\n",
    "    return new_stats\n",
    "\n",
    "def binarize_image(img, threshold=127):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply thresholding with background-foreground inversion\n",
    "    binary_img = cv2.threshold(img, threshold, 1, cv2.THRESH_BINARY_INV)[1]\n",
    "\n",
    "    return binary_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fae380c-e3a4-45c8-992e-a2b3dea1597c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'%': 0, '*': 1, '+': 2, '-': 3, '0': 4, '1': 5, '2': 6, '3': 7, '4': 8, '5': 9, '6': 10, '7': 11, '8': 12, '9': 13, '[': 14, ']': 15}\n",
    "reverse_mapping = {0: '%', 1: '*', 2: '+', 3: '-', 4: '0', 5: '1', 6: '2', 7: '3', 8: '4', 9: '5', 10: '6', 11: '7', 12: '8', 13: '9', 14: '[', 15: ']'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c29fdad-0f9d-451f-8db6-9de59bffe8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('./fine_tuned_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4b64beb-5ac2-4389-b605-b9209c579aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input_img(img, bb):\n",
    "    (x, y, w, h, a) = bb\n",
    "    cropped = img[y:y+h, x:x+w]\n",
    "    cropped = cv2.resize(cropped, (28, 28))\n",
    "    return binarize_image(cropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84991e4a-eb89-4137-bcc8-3188de19873a",
   "metadata": {},
   "source": [
    "### If want to change img path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fb774a7-3060-4c38-814a-879f7671e36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['handwritten-full-test/.ipynb_checkpoints',\n",
       " 'handwritten-full-test/x+9.jpg',\n",
       " 'handwritten-full-test/6_div_3.jpg',\n",
       " 'handwritten-full-test/1+1=.jpg',\n",
       " 'handwritten-full-test/8+4.jpg',\n",
       " 'handwritten-full-test/1+1.jpg',\n",
       " 'handwritten-full-test/3.3.jpg',\n",
       " 'handwritten-full-test/2x2.jpg']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_dir = 'handwritten-full-test'\n",
    "images = [f.path for f in os.scandir(images_dir)]\n",
    "images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a6c0d9-0d08-48c3-b499-c604d08da337",
   "metadata": {},
   "source": [
    "## Run Below for different img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6e42f7b-cd48-4da7-b376-7f49c52ef647",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = images[5]\n",
    "img = cv2.imread(img)\n",
    "bbs = get_character_bounding_boxes(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "102b2ddb-d390-4f76-9231-35629af8c306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 171ms/step\n",
      "1\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "+\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for bb in bbs:\n",
    "    char = format_input_img(img, bb)\n",
    "    char = char.reshape(-1, 28, 28, 1) \n",
    "    yh_test = model.predict(char).argmax(axis=1)\n",
    "    print(reverse_mapping[yh_test[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9262941b-2e7f-4f06-9242-0a680654a132",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
